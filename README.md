# End-to-End MLOps Pipeline on Azure â€“ Churn Prediction

This project demonstrates an end-to-end MLOps workflow for deploying a machine learning model on Azure using Docker and Kubernetes.

## ðŸ”¹ Project Overview
The goal of this project is to predict customer churn using a machine learning model and deploy it as a scalable REST API.

## ðŸ”¹ Tech Stack
- Python
- scikit-learn
- FastAPI
- Docker
- Azure Container Registry (ACR)
- Azure Kubernetes Service (AKS)

## ðŸ”¹ Architecture

## ðŸ”¹ Project Structure
- `src/` â€“ Training, preprocessing, and evaluation scripts
- `model/` â€“ Saved model and preprocessing pipeline
- `docker/` â€“ Dockerfile and FastAPI inference app
- `pipelines/` â€“ MLOps pipeline components
- `requirements.txt` â€“ Python dependencies

## ðŸ”¹ Model Training
- Data preprocessing using pandas and scikit-learn
- Categorical encoding and feature scaling
- Model training and evaluation
- Model and preprocessing pipeline saved using joblib

## ðŸ”¹ Deployment
- FastAPI used to expose the model as a REST API
- Docker used to containerize the inference service
- Image pushed to Azure Container Registry
- Deployed to Azure Kubernetes Service for scalable inference

## ðŸ”¹ Key Learnings
- Containerizing ML models using Docker
- Deploying ML services on Kubernetes
- Handling real-world MLOps deployment challenges
- Ensuring consistent preprocessing between training and inference

## ðŸ”¹ Future Improvements
- Add CI/CD using Azure DevOps
- Integrate Azure ML for experiment tracking
- Add monitoring and logging

---
